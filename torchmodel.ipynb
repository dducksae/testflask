{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, random\n",
    "from glob import glob\n",
    "import cv2\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 폴더 수: 3\n",
      "총 이미지 수: 6133\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 루트 폴더\n",
    "dataset_root = 'C:/Users/User/data/result/'\n",
    "\n",
    "# 모든 클래스 폴더 가져오기\n",
    "class_folders = [f for f in os.listdir(dataset_root) if os.path.isdir(os.path.join(dataset_root, f))]\n",
    "\n",
    "# 각 클래스 폴더 내의 이미지 수 계산\n",
    "total_images = 0\n",
    "for class_folder in class_folders:\n",
    "    class_path = os.path.join(dataset_root, class_folder)\n",
    "    images_in_class = [f for f in os.listdir(class_path) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "    total_images += len(images_in_class)\n",
    "\n",
    "# 결과 출력\n",
    "print(f'클래스 폴더 수: {len(class_folders)}')\n",
    "print(f'총 이미지 수: {total_images}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# 이미지의 사이즈를 변환 후 텐서로 변환 \n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "#폴더의 이미지를 로딩, 라벨링\n",
    "train_dataset = ImageFolder(root='C:/Users/User/data/result/', transform=transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.classes\n",
    "# 학습 결과 시각화\n",
    "train_losses = []  # 학습 손실값을 기록할 리스트\n",
    "train_accuracies = []  # 학습 정확도를 기록할 리스트\n",
    "save_interval = 1\n",
    "\n",
    "# 에포크마다 모델 저장을 위한 경로와 파일명 지정\n",
    "model_save_path = 'C:/Users/User/Desktop/model_result/models'  # 저장할 디렉토리 경로\n",
    "model_name = 'model'  # 저장할 모델 파일명 (에포크 번호가 자동으로 붙음)\n",
    "\n",
    "# 저장할 폴더가 없다면 생성\n",
    "os.makedirs(model_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30] - Loss: 0.8670, Accuracy: 58.23%\n",
      "Epoch [2/30] - Loss: 0.6903, Accuracy: 67.78%\n",
      "Epoch [3/30] - Loss: 0.5847, Accuracy: 74.21%\n",
      "Epoch [4/30] - Loss: 0.5170, Accuracy: 77.68%\n",
      "Epoch [5/30] - Loss: 0.4601, Accuracy: 80.91%\n",
      "Epoch [6/30] - Loss: 0.4223, Accuracy: 83.04%\n",
      "Epoch [7/30] - Loss: 0.3664, Accuracy: 85.60%\n",
      "Epoch [8/30] - Loss: 0.3446, Accuracy: 86.53%\n",
      "Epoch [9/30] - Loss: 0.3179, Accuracy: 87.53%\n",
      "Epoch [10/30] - Loss: 0.3067, Accuracy: 88.50%\n",
      "Epoch [11/30] - Loss: 0.2855, Accuracy: 89.66%\n",
      "Epoch [12/30] - Loss: 0.2583, Accuracy: 90.54%\n",
      "Epoch [13/30] - Loss: 0.2533, Accuracy: 90.62%\n",
      "Epoch [14/30] - Loss: 0.2390, Accuracy: 91.37%\n",
      "Epoch [15/30] - Loss: 0.2168, Accuracy: 92.12%\n",
      "Epoch [16/30] - Loss: 0.2128, Accuracy: 92.48%\n",
      "Epoch [17/30] - Loss: 0.2134, Accuracy: 92.29%\n",
      "Epoch [18/30] - Loss: 0.1864, Accuracy: 93.64%\n",
      "Epoch [19/30] - Loss: 0.1913, Accuracy: 93.10%\n",
      "Epoch [20/30] - Loss: 0.1781, Accuracy: 94.16%\n",
      "Epoch [21/30] - Loss: 0.1612, Accuracy: 94.34%\n",
      "Epoch [22/30] - Loss: 0.1611, Accuracy: 94.36%\n",
      "Epoch [23/30] - Loss: 0.1516, Accuracy: 95.16%\n",
      "Epoch [24/30] - Loss: 0.1500, Accuracy: 94.90%\n",
      "Epoch [25/30] - Loss: 0.1368, Accuracy: 95.16%\n",
      "Epoch [26/30] - Loss: 0.1328, Accuracy: 95.45%\n",
      "Epoch [27/30] - Loss: 0.1273, Accuracy: 95.81%\n",
      "Epoch [28/30] - Loss: 0.1248, Accuracy: 95.87%\n",
      "Epoch [29/30] - Loss: 0.1258, Accuracy: 95.91%\n",
      "Epoch [30/30] - Loss: 0.1044, Accuracy: 96.59%\n"
     ]
    }
   ],
   "source": [
    "class CNNModel(nn.Module) :\n",
    "    # 모델의 레이어\n",
    "    def __init__(self, num_classes) :\n",
    "        super(CNNModel, self).__init__()\n",
    "        #두개의 합성곱, 풀링 레이어(pool), 완전연결레이어(fc1)\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(16 * 16 * 64, num_classes) #이미지 사이즈가 64x64로 변경됨\n",
    "\n",
    "    # 입력데이터의 연산 수행 후 출력\n",
    "    def forward(self, x) :\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 16 * 64)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = CNNModel(num_classes=3)\n",
    "model.to(device)\n",
    "#다중클래스 분류에서 사용하는 손실함수\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 알고리즘(adam)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#학습 수행(epoch = 30)\n",
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_accuracy)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "    if (epoch + 1) % save_interval == 0:\n",
    "        model_filename = f'{model_name}_epoch_{epoch+1}.pt'\n",
    "        model_filepath = os.path.join(model_save_path, model_filename)\n",
    "        torch.save(model.state_dict(), model_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mEpoch\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m     plt\u001b[39m.\u001b[39mlegend([\u001b[39m'\u001b[39m\u001b[39mTrain\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTest\u001b[39m\u001b[39m'\u001b[39m], loc\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m plt_show_loss(train_losses)\n\u001b[0;32m     18\u001b[0m plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m     20\u001b[0m plt_show_acc(train_accuracies)\n",
      "Cell \u001b[1;32mIn[74], line 2\u001b[0m, in \u001b[0;36mplt_show_loss\u001b[1;34m(losses)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplt_show_loss\u001b[39m(losses) :\n\u001b[1;32m----> 2\u001b[0m     plt\u001b[39m.\u001b[39mplot(losses\u001b[39m.\u001b[39;49mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m     plt\u001b[39m.\u001b[39mplot(losses\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m     plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mModel Loss\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "\n",
    "def plt_show_loss(losses) :\n",
    "    plt.plot(losses.history['loss'])\n",
    "    plt.plot(losses.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc=0)\n",
    "\n",
    "def plt_show_acc(accuracies) :\n",
    "    plt.plot(accuracies.history['accuracy'])\n",
    "    plt.plot(accuracies.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc=0)\n",
    "\n",
    "plt_show_loss(train_losses)\n",
    "plt.show()\n",
    "\n",
    "plt_show_acc(train_accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 폴더 내의 모든 이미지 파일 경로 가져오기\n",
    "folder_path = \"C:/Users/User/Desktop/bigdata/imgs/test/\"  # 이미지 폴더 경로\n",
    "image_files = glob.glob(os.path.join(folder_path, \"*.jpg\"))  # jpg 확장자를 가진 이미지 파일들의 경로 리스트\n",
    "class_names = [\"Mink\", \"Porpoise\"]\n",
    "\n",
    "# 모델을 eval 상태로 설정\n",
    "model.eval()\n",
    "\n",
    "# 변환 함수 정의\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "for img_path in image_files:\n",
    "    # 이미지 불러오기\n",
    "    img = Image.open(img_path)\n",
    "    img = preprocess(img)\n",
    "    img = torch.unsqueeze(img, 0)\n",
    "\n",
    "    # 모델로 예측하기\n",
    "    with torch.no_grad():\n",
    "        predictions = model(img)\n",
    "        predictions = F.softmax(predictions[0], dim=0) * 100\n",
    "        class_probs = [prob.item() for prob in predictions]\n",
    "\n",
    "    # 예측 결과 시각화하기\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"Class: {class_name}, Probability: {class_probs[i]:.2f}%\")\n",
    "\n",
    "    predicted_class = torch.argmax(predictions).item()\n",
    "    print(f\"Predicted Class: {class_names[predicted_class]}\")\n",
    "    print(\"=\"*30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
